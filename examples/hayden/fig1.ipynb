{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c5d14e5-a8a9-4aa8-b3c2-3656cba1cb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">loading data ...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mloading data \u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_375421/3224519468.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    128\u001b[39m \n\u001b[32m    129\u001b[39m rprint(\u001b[33m'[blue]loading data ...[/blue]'\u001b[39m)\n\u001b[32m    130\u001b[39m \n\u001b[32m    131\u001b[39m df = pd.read_csv(tsv_path, sep=\u001b[33m'\\t'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m df = df[df.dataset == dataset]\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample:\n\u001b[32m    135\u001b[39m     rng           = np.random.default_rng(seed)\n",
      "\u001b[32m~/helivan-project-generation/venvs/helivan/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "    helm.plot_dkps\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from rich import print as rprint\n",
    "\n",
    "# from utils import dkps_df, onehot_embedding\n",
    "# from dkps.embed import embed_api\n",
    "\n",
    "import numpy as np\n",
    "from graspologic.embed import ClassicalMDS\n",
    "# from graspologic.embed import OmnibusEmbed\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# from .utils import knn_graph\n",
    "\n",
    "\n",
    "class DataKernelPerspectiveSpace:\n",
    "    def __init__(\n",
    "            self,\n",
    "            response_distribution_fn=np.mean,\n",
    "            response_distribution_axis=1,\n",
    "            metric_cmds='euclidean',\n",
    "            n_components_cmds=None,\n",
    "            n_elbows_cmds=2,\n",
    "            dissimilarity=\"precomputed\",\n",
    "        ):\n",
    "        \n",
    "        self.response_distribution_fn   = response_distribution_fn\n",
    "        self.response_distribution_axis = response_distribution_axis\n",
    "        self.metric_cmds                = metric_cmds\n",
    "        self.n_components_cmds          = n_components_cmds\n",
    "        self.n_elbows_cmds              = n_elbows_cmds\n",
    "        self.dissimilarity              = dissimilarity\n",
    "\n",
    "    def fit_transform(self, data, return_dict=True):\n",
    "        \"\"\"\n",
    "        data: dict {model_name: np.array(n_queries, n_replicates, embedding_dim)}\n",
    "        \"\"\"\n",
    "        \n",
    "        # qc checks\n",
    "        assert isinstance(data, dict),                                  'data must be a dict'\n",
    "        assert all([isinstance(x, np.ndarray) for x in data.values()]), 'all values must be numpy arrays'\n",
    "        assert all([x.ndim == 3 for x in data.values()]),               'all arrays must be 3D - np.array(n_queries, n_replicates, embedding_dim)'\n",
    "        assert len(set([x.shape for x in data.values()])) == 1,         'all arrays must have the same shape'\n",
    "\n",
    "        # aggregate over replicates -> (n_models, n_queries, embedding_dim)\n",
    "        X = np.stack([self.response_distribution_fn(v, axis=self.response_distribution_axis) for k,v in data.items()])\n",
    "        n_models, n_queries, embedding_dim = X.shape\n",
    "        \n",
    "        # flatten -> (n_models, n_queries * embedding_dim)\n",
    "        X_flat = X.reshape(len(X), -1)\n",
    "\n",
    "        dist_matrix = squareform(pdist(X_flat, metric=self.metric_cmds)) / np.sqrt(n_queries)\n",
    "        cmds_embds  = ClassicalMDS(n_components=self.n_components_cmds, n_elbows=self.n_elbows_cmds, dissimilarity=self.dissimilarity).fit_transform(dist_matrix)\n",
    "        \n",
    "        if return_dict:\n",
    "            return {key: cmds_embds[i] for i, key in enumerate(data.keys())}\n",
    "        else:\n",
    "            return cmds_embds\n",
    "\n",
    "\n",
    "def make_embedding_dict(df):\n",
    "    model_names  = df.model.unique()\n",
    "    instance_ids = df.instance_id.unique()\n",
    "    \n",
    "    embedding_dict = {}\n",
    "    for model_name in model_names:\n",
    "        sub = df[df.model == model_name]\n",
    "        assert (sub.instance_id.values == instance_ids).all(), f'instance_ids are not the same for model {model_name}'\n",
    "        embedding_dict[model_name] = np.vstack(sub.embedding.values)\n",
    "    \n",
    "    embedding_dict = {k:v[:,None] for k,v in embedding_dict.items()}\n",
    "    \n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "def dkps_df(df, **kwargs):\n",
    "    embedding_dict = make_embedding_dict(df)\n",
    "    return DataKernelPerspectiveSpace(**kwargs).fit_transform(embedding_dict, return_dict=True)\n",
    "\n",
    "\n",
    "# --\n",
    "\n",
    "def onehot_embedding(df, dataset):\n",
    "    if dataset == 'med_qa':\n",
    "        lookup = {'A' : 0, 'B' : 1, 'C' : 2, 'D' : 3}\n",
    "        \n",
    "        embeddings = np.zeros((len(df), 4))\n",
    "        for i, xx in enumerate(df.response.values):\n",
    "            if xx in lookup:\n",
    "                embeddings[i, lookup[xx]] = 1\n",
    "        \n",
    "        df['embedding'] = embeddings.tolist()\n",
    "    \n",
    "    elif 'legalbench' in dataset:\n",
    "        # slightly different - bad values get mapped to 0\n",
    "        n_levels   = len(df.response.unique())\n",
    "        embeddings = np.zeros((len(df), n_levels))\n",
    "        for i, xx in enumerate(df.response.values):\n",
    "            embeddings[i, xx] = 1\n",
    "\n",
    "        df['embedding'] = embeddings.tolist()\n",
    "    else:\n",
    "        raise ValueError(f'{dataset} is not supported for onehot embeddings')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "dataset = 'math:subject=algebra'\n",
    "# dataset = file.split('-score-res')[0]\n",
    "# dataset = dataset.split('-meteor-res')[0]\n",
    "score_col = 'score-res'\n",
    "outdir = '/home/user/helivan-project-generation/ep-dkps-results/results'\n",
    "tsv_path = Path(outdir) / f'{dataset}-{score_col}.tsv'\n",
    "# plot_dir = Path('plots') / dataset.replace(':', '-')\n",
    "\n",
    "\n",
    "rprint('[blue]loading data ...[/blue]')\n",
    "\n",
    "df = pd.read_csv(tsv_path, sep='\\t')\n",
    "df = df[df.dataset == dataset]\n",
    "\n",
    "if sample:\n",
    "    rng           = np.random.default_rng(seed)\n",
    "    uinstance_ids = df.instance_id.unique()\n",
    "    keep          = rng.choice(uinstance_ids, int(len(uinstance_ids) * sample), replace=False)\n",
    "    df            = df[df.instance_id.isin(keep)]\n",
    "\n",
    "df = df.sort_values(['model', 'instance_id']).reset_index(drop=True)\n",
    "\n",
    "if score_col != 'score':\n",
    "    print(f'{score_col} -> score')\n",
    "    df['score'] = df[score_col]\n",
    "\n",
    "# BAD_MODELS  = open('bad_models.txt').read().splitlines()\n",
    "\n",
    "# --\n",
    "# QC\n",
    "\n",
    "print(f'{len(df.response.unique())} / {df.shape[0]} responses are unique')\n",
    "instance_ids = df.groupby('model').instance_id.apply(list)\n",
    "assert all([instance_ids.iloc[0] == instance_ids.iloc[i] for i in range(len(instance_ids))]), 'instance_ids are not the same for each model'\n",
    "\n",
    "# --\n",
    "# Get embeddings\n",
    "\n",
    "if embed_model == 'onehot':\n",
    "    df = onehot_embedding(df, dataset=dataset)\n",
    "else:\n",
    "    df['embedding'] = list(embed_api(\n",
    "        provider   = embed_provider, \n",
    "        input_strs = [str(xx) for xx in df.response.values],\n",
    "        model      = embed_model\n",
    "    ))\n",
    "\n",
    "model2score = df.groupby('model').score.mean().to_dict()\n",
    "\n",
    "# --\n",
    "# Plot 1.a - whole DKPS\n",
    "\n",
    "P = dkps_df(df, n_components_cmds=2)\n",
    "P = np.vstack([P[m] for m in model2score.keys()])\n",
    "\n",
    "_ = plt.scatter(P[:, 0], P[:,1], c=model2score.values(), cmap='viridis')\n",
    "_ = plt.xticks([])\n",
    "_ = plt.yticks([])\n",
    "_ = plt.xlabel('DKPS-0')\n",
    "_ = plt.ylabel('DKPS-1')\n",
    "_ = plt.grid('both', alpha=0.25, c='gray')\n",
    "_ = plt.title(f'DKPS - {dataset}')\n",
    "_ = plt.colorbar(label='Score')\n",
    "_ = plt.savefig(plot_dir / 'dkps.png')\n",
    "_ = plt.close()\n",
    "\n",
    "# # --\n",
    "# # Plot 1.b - whole DKPS, bad models removed\n",
    "\n",
    "# thresh     = np.percentile(list(model2score.values()), 10)\n",
    "# BAD_MODELS = [m for m in model2score.keys() if model2score[m] < thresh]\n",
    "\n",
    "# _model2score = {m:model2score[m] for m in model2score.keys() if m not in BAD_MODELS}\n",
    "# P = dkps_df(df[~df.model.isin(BAD_MODELS)], n_components_cmds=2)\n",
    "# P = np.vstack([P[m] for m in _model2score.keys()])\n",
    "\n",
    "# _ = plt.scatter(P[:, 0], P[:,1], c=_model2score.values(), cmap='viridis')\n",
    "# _ = plt.xticks([])\n",
    "# _ = plt.yticks([])\n",
    "# _ = plt.xlabel('DKPS-0')\n",
    "# _ = plt.ylabel('DKPS-1')\n",
    "# _ = plt.grid('both', alpha=0.25, c='gray')\n",
    "# _ = plt.title(f'DKPS - {dataset}')\n",
    "# _ = plt.colorbar(label='Score')\n",
    "# _ = plt.savefig(plot_dir / 'dkps-excl.png')\n",
    "# _ = plt.close()\n",
    "\n",
    "# --\n",
    "# Plot 2 - grid, varying number of instances and models\n",
    "\n",
    "uinstance_ids = np.random.choice(df.instance_id.unique(), size=min(50, len(df.instance_id.unique())), replace=False)\n",
    "umodels       = np.random.permutation(df.model.unique())\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 10))\n",
    "\n",
    "Ps = {}\n",
    "for c, n_instances in enumerate([2, 10, len(uinstance_ids)]):\n",
    "    _instance_ids = uinstance_ids[:n_instances]\n",
    "    for r, n_models in enumerate([20, len(umodels)]):\n",
    "        _models      = umodels[:n_models]\n",
    "        _model2score = {m:model2score[m] for m in _models}\n",
    "        \n",
    "        df_sub = df[df.instance_id.isin(_instance_ids)]\n",
    "        df_sub = df_sub[df_sub.model.isin(_models)]\n",
    "        P_sub  = dkps_df(df_sub, n_components_cmds=2)\n",
    "        P_sub  = np.vstack([P_sub[m] for m in _model2score.keys()])\n",
    "\n",
    "        ax = axes[r, c]\n",
    "\n",
    "        scatter = ax.scatter(P_sub[:, 0], P_sub[:, 1], c=list(_model2score.values()), cmap='viridis')\n",
    "        _ = ax.set_xticks([])\n",
    "        _ = ax.set_yticks([])\n",
    "        _ = ax.set_xlabel('DKPS-0')\n",
    "        _ = ax.set_ylabel('DKPS-1')\n",
    "        _ = ax.grid('both', alpha=0.25, c='gray')\n",
    "        _ = ax.set_title(f'n_models={n_models} | n_instances={n_instances}')\n",
    "\n",
    "_ = plt.suptitle(f'DKPS - {dataset}')\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "# Add colorbar to the figure\n",
    "cbar = plt.colorbar(scatter, ax=axes, shrink=0.8, aspect=20)\n",
    "cbar.set_label('Score')\n",
    "\n",
    "_ = plt.savefig(plot_dir / 'dkps-grid.png')\n",
    "_ = plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b8492-3dc2-4b68-a080-e687141f5121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1abb57b-78e6-40f3-ba84-81667c53d6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'math:subject=algebra'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helivan",
   "language": "python",
   "name": "helivan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
